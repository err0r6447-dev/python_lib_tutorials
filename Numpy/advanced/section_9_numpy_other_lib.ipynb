{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ü§ù Section 8: Interfacing NumPy with Other Libraries ‚Äî Real-World Applications\n",
    "\n",
    "NumPy is not an isolated library ‚Äî it‚Äôs the **numerical foundation** for nearly every major Python data and AI framework. \n",
    "\n",
    "In this section, you‚Äôll learn how to seamlessly interface NumPy arrays with:\n",
    "- **pandas** for data manipulation\n",
    "- **matplotlib** for visualization\n",
    "- **scikit-learn** for machine learning\n",
    "- **Numba** for performance acceleration\n",
    "\n",
    "You‚Äôll also see how NumPy enables **zero-copy data sharing** across these libraries, boosting performance for real-world workloads."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üì¶ 1. NumPy + Pandas: Efficient Data Wrangling\n",
    "\n",
    "Pandas DataFrames are built on top of NumPy arrays. Understanding this relationship helps you:\n",
    "- Transfer data efficiently between pandas and NumPy\n",
    "- Handle conversions without unnecessary copying\n",
    "- Work with structured numerical data in analytics pipelines"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Create a NumPy array simulating product sales data\n",
    "np.random.seed(42)\n",
    "sales_data = np.random.randint(50, 500, size=(10, 3))\n",
    "columns = ['Product_A', 'Product_B', 'Product_C']\n",
    "\n",
    "# Convert to pandas DataFrame\n",
    "df = pd.DataFrame(sales_data, columns=columns)\n",
    "print(\"DataFrame built from NumPy array:\\n\", df.head(), '\\n')\n",
    "\n",
    "# Back to NumPy array for numerical processing\n",
    "arr = df.to_numpy()\n",
    "print(\"Converted back to NumPy array:\\n\", arr[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚úÖ NumPy‚Äìpandas conversions are **zero-copy** when dtypes are compatible ‚Äî meaning data is shared, not duplicated.\n",
    "\n",
    "This makes NumPy essential for **ETL pipelines**, **data cleaning**, and **feature preprocessing** in analytics workflows."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìä 2. NumPy + Matplotlib: Visualization at Scale\n",
    "\n",
    "Most Matplotlib plotting functions accept NumPy arrays directly. \n",
    "This is especially useful when visualizing large-scale simulation or sensor data.\n",
    "\n",
    "### Real-World Example: Analyzing Stock Price Trends"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Simulate 1 year of daily stock price data using NumPy\n",
    "days = np.arange(365)\n",
    "base_price = 100 + np.cumsum(np.random.normal(0, 1, size=365))\n",
    "\n",
    "# Compute moving averages with NumPy\n",
    "short_ma = np.convolve(base_price, np.ones(7)/7, mode='valid')\n",
    "long_ma = np.convolve(base_price, np.ones(30)/30, mode='valid')\n",
    "\n",
    "# Plot results\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.plot(days, base_price, label='Daily Price', alpha=0.6)\n",
    "plt.plot(days[6:], short_ma, label='7-Day MA', color='orange')\n",
    "plt.plot(days[29:], long_ma, label='30-Day MA', color='red')\n",
    "plt.title('Stock Price Trend with Moving Averages')\n",
    "plt.xlabel('Day')\n",
    "plt.ylabel('Price ($)')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚úÖ NumPy provides fast numerical computation, while Matplotlib turns those results into visuals.\n",
    "\n",
    "Together they form the **core of exploratory data analysis** (EDA) in finance, science, and engineering."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ü§ñ 3. NumPy + Scikit-Learn: Machine Learning Pipelines\n",
    "\n",
    "Scikit-learn uses NumPy arrays as its **primary data structure**. \n",
    "All models and transformers expect NumPy-like input (or objects convertible to it).\n",
    "\n",
    "### Real-World Example: Predicting House Prices"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Generate synthetic housing data\n",
    "np.random.seed(0)\n",
    "n_samples = 500\n",
    "size = np.random.normal(1500, 300, n_samples)  # square feet\n",
    "bedrooms = np.random.randint(1, 5, n_samples)\n",
    "age = np.random.randint(0, 30, n_samples)\n",
    "\n",
    "# Price is a linear combination + noise\n",
    "price = 50_000 + (size * 200) + (bedrooms * 10_000) - (age * 1000) + np.random.normal(0, 10_000, n_samples)\n",
    "\n",
    "# Create NumPy feature matrix and target vector\n",
    "X = np.column_stack((size, bedrooms, age))\n",
    "y = price\n",
    "\n",
    "# Train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Fit model\n",
    "model = LinearRegression().fit(X_train, y_train)\n",
    "print(\"Coefficients:\", model.coef_)\n",
    "print(\"Intercept:\", model.intercept_)\n",
    "print(\"R¬≤ on test data:\", model.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚úÖ All features (`X`) and targets (`y`) are **NumPy arrays**. \n",
    "\n",
    "This tight integration allows seamless preprocessing and model training pipelines.\n",
    "You can also use `pandas.DataFrame.values` or `df.to_numpy()` directly in ML models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚ö° 4. NumPy + Numba: Accelerating Computations\n",
    "\n",
    "[Numba](https://numba.pydata.org/) uses **JIT compilation** to turn NumPy-based Python functions into optimized machine code.\n",
    "\n",
    "This is ideal for accelerating inner loops or custom numerical kernels that can‚Äôt be vectorized easily."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "from numba import njit\n",
    "import time\n",
    "\n",
    "# Plain NumPy-based function (slow loop)\n",
    "def moving_average(arr, window):\n",
    "    result = np.empty(len(arr) - window + 1)\n",
    "    for i in range(len(result)):\n",
    "        result[i] = np.mean(arr[i:i+window])\n",
    "    return result\n",
    "\n",
    "# JIT-compiled version\n",
    "@njit\n",
    "def moving_average_fast(arr, window):\n",
    "    result = np.empty(len(arr) - window + 1)\n",
    "    for i in range(len(result)):\n",
    "        result[i] = np.mean(arr[i:i+window])\n",
    "    return result\n",
    "\n",
    "# Benchmark\n",
    "data = np.random.random(1_000_000)\n",
    "start = time.time(); moving_average(data, 50); print(f'Python: {time.time()-start:.3f}s')\n",
    "start = time.time(); moving_average_fast(data, 50); print(f'Numba JIT: {time.time()-start:.3f}s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚úÖ The **Numba-accelerated function** can be 10‚Äì100√ó faster depending on complexity ‚Äî perfect for scientific computing and finance simulations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîç Under the Hood\n",
    "\n",
    "All these libraries ‚Äî pandas, scikit-learn, Numba, and others ‚Äî rely on NumPy‚Äôs **array interface** (`__array_interface__`) to access underlying memory buffers.\n",
    "\n",
    "This interface allows **zero-copy interoperability**, meaning large datasets don‚Äôt have to be copied between tools ‚Äî a crucial performance advantage in large pipelines."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚ö†Ô∏è Best Practices & Pitfalls\n",
    "\n",
    "**Best Practices:**\n",
    "- Use `df.to_numpy()` instead of `values` (future-proof).\n",
    "- Always ensure dtype consistency when passing arrays between libraries.\n",
    "- For performance-critical loops, prefer JIT compilation (Numba) or vectorized NumPy functions.\n",
    "- Avoid unnecessary DataFrame <-> NumPy conversions ‚Äî work natively where possible.\n",
    "\n",
    "**Pitfalls:**\n",
    "- Copying large arrays between pandas, NumPy, and ML libraries can silently double memory usage.\n",
    "- Some libraries (e.g., older scikit-learn versions) may coerce `float64` to `float32` ‚Äî check model expectations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üß© Challenge Exercise\n",
    "\n",
    "**Task:** Build a mini data pipeline:\n",
    "1. Generate synthetic e-commerce sales data with NumPy.\n",
    "2. Load it into pandas, compute rolling weekly averages, and convert back to NumPy.\n",
    "3. Train a regression model (using scikit-learn) to predict next week‚Äôs sales.\n",
    "4. Use Numba to optimize one computational step.\n",
    "\n",
    "üéØ *Goal:* Practice end-to-end interoperability and performance tuning in a realistic workflow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# --- End of Section 8 ---\n",
    "\n",
    "Next up ‚Üí **Advanced Capstone: Building a High-Performance Numerical Pipeline**, where we‚Äôll combine memory mapping, Numba, and linear algebra for large-scale analytics."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
