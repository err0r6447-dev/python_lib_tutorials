{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üìä Section 4: Aggregation, Reduction, and Statistical Operations in NumPy\n",
    "\n",
    "NumPy shines not just in elementwise computation but in **aggregating** and **summarizing** large datasets efficiently.\n",
    "\n",
    "In this section, we‚Äôll explore how **reductions** like `sum()`, `mean()`, `min()`, and `std()` work internally, how to use them across axes, and how to chain them to compute advanced statistics efficiently.\n",
    "\n",
    "---\n",
    "## üéØ Learning Objectives\n",
    "\n",
    "By the end of this section, you‚Äôll:\n",
    "- Understand the concept of **reductions** and **axes**.\n",
    "- Perform **aggregations** across specific dimensions.\n",
    "- Learn to use **built-in statistical functions** in NumPy.\n",
    "- Optimize aggregations for **speed and memory efficiency**.\n",
    "- Avoid common pitfalls like axis confusion or unintended data collapse.\n",
    "\n",
    "---\n",
    "## üß† 1. What is a Reduction?\n",
    "\n",
    "A *reduction* is any operation that **reduces the number of dimensions** by aggregating values along one or more axes.\n",
    "\n",
    "For example, computing a mean of a 2D array along rows reduces it to 1D ‚Äî one mean per row."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "\n",
    "# Create a 2D array of simulated sensor readings\n",
    "data = np.array([\n",
    "    [23.1, 24.5, 22.8, 23.9],\n",
    "    [25.4, 24.8, 26.1, 25.7],\n",
    "    [22.5, 21.9, 23.0, 22.7]\n",
    "])\n",
    "\n",
    "print(\"Data:\\n\", data)\n",
    "\n",
    "# Compute simple reductions\n",
    "print(\"\\nOverall mean:\", np.mean(data))\n",
    "print(\"Row-wise means:\", np.mean(data, axis=1))\n",
    "print(\"Column-wise means:\", np.mean(data, axis=0))"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice how the **axis** parameter controls *which dimension collapses*.\n",
    "\n",
    "- `axis=0` ‚Üí collapse rows ‚Üí operate column-wise.\n",
    "- `axis=1` ‚Üí collapse columns ‚Üí operate row-wise.\n",
    "\n",
    "---\n",
    "## ‚öôÔ∏è 2. Common Aggregation Functions\n",
    "\n",
    "NumPy provides many efficient aggregation functions, including:\n",
    "\n",
    "| Function | Description |\n",
    "|-----------|--------------|\n",
    "| `np.sum()` | Sum of elements |\n",
    "| `np.mean()` | Arithmetic mean |\n",
    "| `np.std()` | Standard deviation |\n",
    "| `np.var()` | Variance |\n",
    "| `np.min()` / `np.max()` | Minimum / Maximum |\n",
    "| `np.prod()` | Product of all elements |\n",
    "| `np.median()` | Median value |\n",
    "| `np.percentile()` | Percentile statistics |\n",
    "\n",
    "All of these accept the same key arguments: `axis`, `dtype`, and `keepdims`."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Example: axis and keepdims\n",
    "sum_rows = np.sum(data, axis=1, keepdims=True)\n",
    "print(\"Sum of each row (kept as 2D):\\n\", sum_rows)\n",
    "\n",
    "# Normalizing by row sums\n",
    "normalized = data / sum_rows\n",
    "print(\"\\nRow-normalized data:\\n\", normalized)\n",
    "\n",
    "# Compute standard deviation for each sensor (column)\n",
    "print(\"\\nStandard deviation per column:\", np.std(data, axis=0))"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚úÖ `keepdims=True` keeps the result‚Äôs dimensionality consistent, which makes broadcasting back into the original shape easier.\n",
    "\n",
    "---\n",
    "## üìà 3. Realistic Example ‚Äî Daily Temperature Aggregation\n",
    "\n",
    "Let‚Äôs simulate daily temperature readings (in ¬∞C) for 7 days from 5 weather stations and perform aggregations."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "temps = np.random.normal(loc=25, scale=3, size=(7, 5))  # 7 days √ó 5 stations\n",
    "print(\"Temperatures (¬∞C):\\n\", np.round(temps, 2))\n",
    "\n",
    "# Mean temperature per day\n",
    "daily_mean = np.mean(temps, axis=1)\n",
    "# Mean temperature per station\n",
    "station_mean = np.mean(temps, axis=0)\n",
    "# Overall stats\n",
    "overall_min = np.min(temps)\n",
    "overall_max = np.max(temps)\n",
    "overall_std = np.std(temps)\n",
    "\n",
    "print(\"\\nDaily mean temperatures:\", np.round(daily_mean, 2))\n",
    "print(\"Station mean temperatures:\", np.round(station_mean, 2))\n",
    "print(f\"\\nOverall Min: {overall_min:.2f}, Max: {overall_max:.2f}, Std: {overall_std:.2f}\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NumPy‚Äôs aggregations are computed in **compiled C code**, so even large 1000√ó1000 matrices reduce nearly instantly.\n",
    "\n",
    "---\n",
    "## üß© 4. Using `dtype` for Precision and Stability\n",
    "\n",
    "When aggregating integer arrays, precision can be lost due to overflow. You can specify the output `dtype` for safer computation."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "arr_int = np.arange(1_000_000, dtype=np.int16)\n",
    "print(\"Default sum (may overflow):\", np.sum(arr_int))\n",
    "print(\"Safe sum with dtype=int64:\", np.sum(arr_int, dtype=np.int64))"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Always control the `dtype` when working with large integer arrays to ensure numerical stability.\n",
    "\n",
    "---\n",
    "## ‚ö° 5. Advanced: Weighted and Percentile Aggregations\n",
    "\n",
    "NumPy offers tools like `np.average()` (for weighted means) and `np.percentile()` for quantile-based statistics."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "weights = np.array([0.1, 0.3, 0.4, 0.2])\n",
    "weighted_avg = np.average(data, axis=1, weights=weights)\n",
    "percentile_75 = np.percentile(data, 75)\n",
    "\n",
    "print(\"Weighted average per row:\", np.round(weighted_avg, 2))\n",
    "print(\"75th percentile of all readings:\", np.round(percentile_75, 2))"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Percentiles are extremely useful in data science ‚Äî for instance, identifying outliers or cutoff thresholds.\n",
    "\n",
    "---\n",
    "## üîç Under the Hood: How Reductions Work\n",
    "\n",
    "Internally, NumPy implements reductions using **C loops over contiguous memory** for each axis.\n",
    "\n",
    "For example, `np.sum()` uses a specialized accumulator that iterates efficiently through the array using its **strides** ‚Äî avoiding Python-level iteration.\n",
    "\n",
    "The process:\n",
    "1. Identify the memory layout and stride pattern.\n",
    "2. Collapse elements along the target axis.\n",
    "3. Accumulate the result using optimized C functions.\n",
    "\n",
    "If arrays are **non-contiguous** (e.g., from slicing), NumPy still works ‚Äî but slightly slower because of non-linear memory access.\n",
    "\n",
    "---\n",
    "## üß≠ Best Practices and Pitfalls\n",
    "\n",
    "‚úÖ Use `axis` explicitly ‚Äî avoid confusion about which dimension is reduced.\n",
    "\n",
    "‚úÖ Use `keepdims=True` when you‚Äôll broadcast results back into the original array.\n",
    "\n",
    "‚úÖ Always specify `dtype` when summing large or mixed-type arrays.\n",
    "\n",
    "‚úÖ Use NumPy‚Äôs built-in statistical functions ‚Äî they‚Äôre faster and numerically safer than Python‚Äôs `sum()` or `statistics` module.\n",
    "\n",
    "‚ö†Ô∏è Beware of collapsing all axes accidentally when you forget to specify `axis`.\n",
    "\n",
    "---\n",
    "## üí™ Challenge Exercises\n",
    "\n",
    "1. Create a 10√ó6 array of random integers (0‚Äì99). Compute:\n",
    "   - The mean of each column.\n",
    "   - The maximum of each row.\n",
    "   - The overall standard deviation.\n",
    "2. Compute the weighted average of a 3√ó4 array using different weights per column.\n",
    "3. Find the 25th, 50th, and 90th percentiles of a random 1D array of 1,000 values.\n",
    "\n",
    "---\n",
    "## üèÅ Summary\n",
    "\n",
    "- **Reductions** collapse dimensions by aggregating along axes.\n",
    "- The **axis** parameter defines the direction of reduction.\n",
    "- **Statistical functions** (`mean`, `std`, `percentile`) are optimized in C.\n",
    "- Use `keepdims` and `dtype` wisely to ensure stability and compatibility.\n",
    "\n",
    "Next up: **Section 5 ‚Äî Boolean Masking and Conditional Filtering**, where you‚Äôll learn how to apply logic and selection directly to arrays using Boolean masks."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.x"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
