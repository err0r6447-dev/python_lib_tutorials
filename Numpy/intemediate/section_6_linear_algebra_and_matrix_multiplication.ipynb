{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üßÆ Section 6: Linear Algebra and Matrix Operations\n",
    "\n",
    "NumPy provides a powerful set of tools for linear algebra ‚Äî the mathematical backbone of many scientific and machine learning applications.\n",
    "\n",
    "In this section, we'll explore matrix multiplication, solving systems of equations, decompositions, and the connection between NumPy arrays and matrix algebra."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚öôÔ∏è 1. NumPy‚Äôs Linear Algebra Foundations\n",
    "\n",
    "NumPy‚Äôs `linalg` module builds on **BLAS** (Basic Linear Algebra Subprograms) and **LAPACK**, which are highly optimized C/Fortran libraries.\n",
    "\n",
    "- `np.dot()` and the `@` operator perform matrix multiplication.\n",
    "- `np.linalg.solve()` solves systems of equations efficiently.\n",
    "- `np.linalg.inv()`, `np.linalg.eig()`, and `np.linalg.svd()` perform common matrix operations.\n",
    "\n",
    "Let's start by constructing and operating on matrices."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "\n",
    "# Example matrices (2D arrays)\n",
    "A = np.array([[3, 2], [1, 4]])\n",
    "B = np.array([[5, 1], [2, 3]])\n",
    "\n",
    "print(\"Matrix A:\\n\", A)\n",
    "print(\"Matrix B:\\n\", B)\n",
    "\n",
    "# Matrix multiplication using @ (preferred)\n",
    "C = A @ B\n",
    "print(\"A @ B =\\n\", C)\n",
    "\n",
    "# Element-wise multiplication for comparison\n",
    "E = A * B\n",
    "print(\"Element-wise (Hadamard) product =\\n\", E)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üß© 2. Solving Linear Systems\n",
    "\n",
    "In many scientific and engineering problems, we need to solve systems of equations like:\n",
    "\n",
    "$A\\vec{x} = \\vec{b}$\n",
    "\n",
    "NumPy‚Äôs `np.linalg.solve()` uses LU decomposition internally and avoids explicitly computing the inverse (which can be numerically unstable)."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Solve A¬∑x = b\n",
    "b = np.array([8, 7])\n",
    "x = np.linalg.solve(A, b)\n",
    "\n",
    "print(\"Solution x =\", x)\n",
    "\n",
    "# Verify correctness: A @ x ‚âà b\n",
    "print(\"Check (A @ x):\", A @ x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìê 3. Matrix Properties and Inverses\n",
    "\n",
    "NumPy provides direct functions for computing determinants, inverses, and transposes.\n",
    "Remember: in practice, computing a matrix inverse explicitly is **not recommended** for solving systems ‚Äî prefer `np.linalg.solve()` for numerical stability."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Determinant\n",
    "det_A = np.linalg.det(A)\n",
    "print(\"Determinant of A:\", det_A)\n",
    "\n",
    "# Inverse (use with caution)\n",
    "A_inv = np.linalg.inv(A)\n",
    "print(\"Inverse of A:\\n\", A_inv)\n",
    "\n",
    "# Check: A @ A_inv ‚âà I\n",
    "I = A @ A_inv\n",
    "print(\"A @ A_inv =\\n\", I)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üß≠ 4. Eigenvalues and Eigenvectors\n",
    "\n",
    "Eigenvalues and eigenvectors are fundamental in machine learning, quantum mechanics, and PCA.\n",
    "They describe intrinsic properties of linear transformations.\n",
    "\n",
    "NumPy‚Äôs `np.linalg.eig()` returns both ‚Äî the scalars (Œª) and vectors (v) satisfying:\n",
    "\n",
    "$A v = \\lambda v$"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Eigen decomposition\n",
    "eig_vals, eig_vecs = np.linalg.eig(A)\n",
    "\n",
    "print(\"Eigenvalues:\", eig_vals)\n",
    "print(\"Eigenvectors:\\n\", eig_vecs)\n",
    "\n",
    "# Verify the relationship A¬∑v = Œª¬∑v for the first eigenpair\n",
    "v = eig_vecs[:, 0]\n",
    "Œª = eig_vals[0]\n",
    "\n",
    "print(\"Check (A @ v):\", A @ v)\n",
    "print(\"Check (Œª * v):\", Œª * v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîç 5. Singular Value Decomposition (SVD)\n",
    "\n",
    "SVD is a powerful factorization technique used in data compression, noise reduction, and dimensionality reduction (e.g., PCA).\n",
    "\n",
    "$A = UŒ£V^T$\n",
    "\n",
    "NumPy‚Äôs `np.linalg.svd()` performs this efficiently even for large matrices."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Create a rectangular matrix\n",
    "M = np.array([[2, 4, 1], [3, 5, 7]])\n",
    "\n",
    "# Perform Singular Value Decomposition\n",
    "U, S, VT = np.linalg.svd(M)\n",
    "\n",
    "print(\"U matrix:\\n\", U)\n",
    "print(\"Singular values:\", S)\n",
    "print(\"V^T matrix:\\n\", VT)\n",
    "\n",
    "# Reconstruct M from components\n",
    "M_reconstructed = U @ np.diag(S) @ VT\n",
    "print(\"Reconstructed M:\\n\", M_reconstructed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚öôÔ∏è Under the Hood: BLAS, LAPACK, and Performance\n",
    "\n",
    "- NumPy delegates heavy computation to **BLAS** (Basic Linear Algebra Subprograms) and **LAPACK**, written in C/Fortran.\n",
    "- These are optimized for cache locality and parallel CPU execution.\n",
    "- Modern NumPy automatically detects available BLAS (like OpenBLAS, MKL) for speed.\n",
    "- Operations like matrix multiplication and SVD use these routines under the hood.\n",
    "\n",
    "You can inspect which BLAS your system uses:\n",
    "```python\n",
    "np.__config__.show()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚úÖ Best Practices & Pitfalls\n",
    "\n",
    "‚úî Prefer `A @ B` or `np.dot()` for matrix multiplication ‚Äî both are optimized C routines.\n",
    "‚úî Use `np.linalg.solve()` instead of computing explicit inverses.\n",
    "‚úî Always check condition numbers (`np.linalg.cond(A)`) before solving ‚Äî ill-conditioned matrices amplify numerical errors.\n",
    "‚úî SVD and eigen-decomposition can be **computationally expensive** ‚Äî use only when necessary.\n",
    "\n",
    "**Common mistakes:**\n",
    "- Confusing element-wise (`*`) with matrix (`@`) multiplication.\n",
    "- Forgetting that arrays default to row-major (C-order) memory layout.\n",
    "- Ignoring numerical instability in near-singular matrices."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üí™ Challenge Exercise\n",
    "\n",
    "**Task:**\n",
    "Given a 3√ó3 matrix representing linear transformations of 3D points, find its **eigenvalues**, **eigenvectors**, and **determinant**. Then verify whether it‚Äôs invertible.\n",
    "\n",
    "*Hint:* Use `np.linalg.det()`, `np.linalg.eig()`, and `np.linalg.inv()` to explore properties.\n",
    "\n",
    "```python\n",
    "# Your code here\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# --- End of Section 6 ‚Äî Continue to Section 7 ---\n",
    "\n",
    "In the next section, we'll focus on **Performance Optimization and Memory Efficiency**, learning how to profile, vectorize, and optimize NumPy computations for real-world workloads."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
