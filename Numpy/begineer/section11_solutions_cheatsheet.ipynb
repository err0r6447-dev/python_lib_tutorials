{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸ§© Final Section â€” Challenge Solutions + NumPy Cheat Sheet\n",
    "\n",
    "Congratulations on reaching the end of this hands-on NumPy tutorial! ðŸŽ‰  \n",
    "This final section provides:\n",
    "\n",
    "1. **Solutions to selected challenges** from earlier sections, with brief commentary.\n",
    "2. A **practical NumPy cheat sheet** summarizing essential functions, idioms, and best practices.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ§  Challenge Solutions\n",
    "\n",
    "Below are concise, commented solutions to the major exercises.\n",
    "They emphasize reasoning, not just results â€” each demonstrates NumPyâ€™s vectorized mindset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### âœ… Challenge 1: Basic Array Creation and Summary Stats\n",
    "Create a 3Ã—3 sales array and compute totals and averages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "sales = np.array([\n",
    "    [120, 135, 150],\n",
    "    [80,  90,  100],\n",
    "    [200, 210, 195]\n",
    "])\n",
    "\n",
    "print(\"Total sales:\", sales.sum())\n",
    "print(\"Average per product:\", sales.mean(axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### âœ… Challenge 2: Reshaping and Indexing\n",
    "Reshape a 1D array into 2D and extract specific rows and columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.arange(1, 13)\n",
    "a2d = a.reshape(3, 4)\n",
    "print(a2d)\n",
    "\n",
    "second_row = a2d[1]\n",
    "last_column = a2d[:, -1]\n",
    "\n",
    "print(\"Second row:\", second_row)\n",
    "print(\"Last column:\", last_column)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### âœ… Challenge 3: Broadcasting and Vectorization\n",
    "Apply a 1D discount array across a 2D product price matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prices = np.array([\n",
    "    [100, 150, 200],\n",
    "    [90,  140, 180]\n",
    "])\n",
    "discounts = np.array([0.1, 0.15, 0.2])\n",
    "\n",
    "# Broadcasting applies discounts across each column\n",
    "final_prices = prices * (1 - discounts)\n",
    "final_prices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### âœ… Challenge 4: Aggregations and Axis Operations\n",
    "Compute column-wise and row-wise statistics efficiently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.random.randint(50, 100, size=(4, 5))\n",
    "print(data)\n",
    "\n",
    "col_means = np.mean(data, axis=0)\n",
    "row_sums = np.sum(data, axis=1)\n",
    "\n",
    "print(\"Column means:\", col_means)\n",
    "print(\"Row sums:\", row_sums)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### âœ… Challenge 5: Boolean Masking and Conditional Logic\n",
    "Filter all sales greater than 150 and replace low ones with the mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales = np.array([120, 200, 150, 90, 300, 50])\n",
    "mask = sales > 150\n",
    "print(\"High sales:\", sales[mask])\n",
    "\n",
    "mean_sales = sales.mean()\n",
    "sales[sales < mean_sales] = mean_sales\n",
    "sales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### âœ… Challenge 6: Randomness and Reproducibility\n",
    "Simulate reproducible random samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.default_rng(seed=123)\n",
    "sample = rng.normal(50, 10, size=10)\n",
    "print(sample)\n",
    "print(\"Mean:\", np.mean(sample), \"Std:\", np.std(sample))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### âœ… Challenge 7: Memory and Dtype Performance\n",
    "Compare memory usage of float64 vs float32 arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr64 = np.ones((1000, 1000), dtype=np.float64)\n",
    "arr32 = np.ones((1000, 1000), dtype=np.float32)\n",
    "print(\"float64 size:\", arr64.nbytes / 1024, \"KB\")\n",
    "print(\"float32 size:\", arr32.nbytes / 1024, \"KB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### âœ… Challenge 8: IoT Sensor Mini Project (Summary)\n",
    "Compute average daily temperature and detect anomalies (values 2 SDs above mean)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_data = np.random.normal(22, 3, size=(30, 24))  # 30 days Ã— 24 hours\n",
    "daily_avg = temp_data.mean(axis=1)\n",
    "overall_mean, overall_std = daily_avg.mean(), daily_avg.std()\n",
    "anomalies = np.where(daily_avg > overall_mean + 2 * overall_std)[0]\n",
    "anomalies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### âœ… Challenge 9: Stock Portfolio Optimization (Summary)\n",
    "Calculate weighted annual return and identify highest contributor to variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = np.array([0.4, 0.2, 0.3, 0.1])\n",
    "returns = np.random.normal(0.001, 0.02, size=(252, 4))\n",
    "portfolio_returns = returns @ weights\n",
    "\n",
    "# Annualized metrics\n",
    "annual_return = np.mean(portfolio_returns) * 252\n",
    "annual_volatility = np.std(portfolio_returns) * np.sqrt(252)\n",
    "\n",
    "cov_matrix = np.cov(returns.T)\n",
    "contributions = weights * (cov_matrix @ weights)\n",
    "\n",
    "print(f\"Annual Return: {annual_return:.2%}\")\n",
    "print(f\"Annual Volatility: {annual_volatility:.2%}\")\n",
    "print(\"Volatility contribution by asset:\", contributions / contributions.sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# ðŸ§­ NumPy Cheat Sheet â€” 20 Most Useful Patterns\n",
    "\n",
    "A compact reference to keep your NumPy intuition sharp.  Each line corresponds to a concept or idiom used throughout the tutorial.\n",
    "\n",
    "### ðŸ”¢ Array Creation\n",
    "- `np.array([...])` â€“ create from list.\n",
    "- `np.zeros((m, n))`, `np.ones((m, n))`, `np.empty((m, n))` â€“ initialized arrays.\n",
    "- `np.arange(start, stop, step)` â€“ integer range.\n",
    "- `np.linspace(start, stop, num)` â€“ evenly spaced float range.\n",
    "- `np.eye(n)` â€“ identity matrix.\n",
    "\n",
    "### ðŸ§© Array Properties\n",
    "- `.shape`, `.ndim`, `.size`, `.dtype`, `.nbytes` â€“ structural attributes.\n",
    "- `arr.T` â€“ transpose.\n",
    "- `arr.reshape(r, c)` â€“ reshape (creates a view when possible).\n",
    "- `arr.ravel()` â€“ flatten view.\n",
    "\n",
    "### âš™ï¸ Math and Aggregation\n",
    "- `np.sum(arr, axis=...)`, `np.mean`, `np.std`, `np.var`, `np.median`, `np.min`, `np.max`.\n",
    "- `np.dot(A, B)` or `A @ B` â€“ matrix multiplication.\n",
    "- `np.cumsum`, `np.diff`, `np.exp`, `np.log`, `np.sqrt` â€“ common ufuncs.\n",
    "- `np.where(condition, x, y)` â€“ vectorized conditional.\n",
    "\n",
    "### ðŸ§  Indexing & Masking\n",
    "- `arr[a:b, c:d]` â€“ slicing.\n",
    "- `arr[mask]` â€“ Boolean indexing.\n",
    "- `np.nonzero(mask)` â€“ indices of True elements.\n",
    "- `arr[arr > threshold] = new_value` â€“ in-place conditional modification.\n",
    "\n",
    "### ðŸŽ² Randomness\n",
    "- `np.random.default_rng(seed)` â€“ new random generator.\n",
    "- `.normal(mean, std, size)`, `.uniform(low, high, size)`, `.integers(low, high, size)`.\n",
    "- `np.random.shuffle(arr)` â€“ random permutation.\n",
    "\n",
    "### ðŸ§® Linear Algebra & Statistics\n",
    "- `np.linalg.inv(A)`, `np.linalg.det(A)`, `np.linalg.eig(A)` â€“ matrix ops.\n",
    "- `np.cov(X.T)`, `np.corrcoef(X.T)` â€“ covariance, correlation.\n",
    "- `np.percentile`, `np.quantile` â€“ summary stats.\n",
    "\n",
    "### ðŸ’¾ Input/Output\n",
    "- `np.save('file.npy', arr)` / `np.load('file.npy')` â€“ binary storage.\n",
    "- `np.savetxt('file.csv', arr, delimiter=',')` / `np.loadtxt('file.csv', delimiter=',')` â€“ text storage.\n",
    "\n",
    "### âš¡ Performance Tips\n",
    "- Prefer vectorized operations over loops.\n",
    "- Use views (`arr.view()`) instead of copies where possible.\n",
    "- Choose proper dtypes (e.g., `float32` vs `float64`).\n",
    "- Profile with `np.info()` and `.nbytes` for memory insights.\n",
    "- Use `np.ascontiguousarray()` for external C-library compatibility.\n",
    "\n",
    "---\n",
    "ðŸ’¡ **Final Thought:** NumPy isnâ€™t just a library â€” itâ€™s a *mindset*.  \n",
    "Mastering it means thinking in **whole-array operations**, not element-wise loops.\n",
    "\n",
    "You now have the foundation to explore advanced topics like broadcasting, parallelism, or integration with pandas, TensorFlow, or SciPy.\n",
    "\n",
    "ðŸŽ¯ **Youâ€™ve completed the NumPy Hands-On Mastery Tutorial.**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.x"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
