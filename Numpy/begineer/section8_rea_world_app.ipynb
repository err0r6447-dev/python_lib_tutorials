{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 8: Advanced Applications and Integration\n",
    "\n",
    "Welcome to the final section of our comprehensive NumPy study guide! ðŸŽ‰\n",
    "\n",
    "At this point, youâ€™ve learned how to create, manipulate, and compute with NumPy arrays â€” efficiently and intuitively. Now weâ€™ll see how those skills apply in **real-world computational problems**.\n",
    "\n",
    "In this section, youâ€™ll:\n",
    "- Explore NumPyâ€™s role in **data science and machine learning pipelines**.\n",
    "- Learn how to perform **matrix computations and linear algebra**.\n",
    "- Integrate NumPy with other Python libraries like **pandas**, **matplotlib**, and **SciPy**.\n",
    "- Understand how to **optimize and profile** NumPy code for performance.\n",
    "\n",
    "Letâ€™s turn theory into practice. ðŸš€"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.1 NumPy in Data Science Workflows\n",
    "\n",
    "NumPy arrays form the **foundation of nearly every data analysis library** in Python â€” including pandas, scikit-learn, and TensorFlow.\n",
    "\n",
    "Letâ€™s start with a practical example: computing **summary statistics** for a dataset and normalizing the data for further processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Simulate a dataset: rows = samples, columns = features\n",
    "data = np.random.randn(1000, 3) * 10 + 50  # 1000 samples, 3 features\n",
    "\n",
    "means = np.mean(data, axis=0)\n",
    "stds = np.std(data, axis=0)\n",
    "normalized = (data - means) / stds\n",
    "\n",
    "print('Means:', means)\n",
    "print('Standard deviations:', stds)\n",
    "print('Shape of normalized data:', normalized.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Why This Matters\n",
    "Normalization is an essential preprocessing step in **machine learning** and **statistics** â€” it ensures that features contribute equally to model training.\n",
    "\n",
    "Notice how easily we expressed this computation using NumPyâ€™s **vectorized operations** â€” no loops, no fuss!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.2 Linear Algebra with `numpy.linalg`\n",
    "\n",
    "Linear algebra underlies many machine learning algorithms and scientific computations. NumPy provides a high-performance linear algebra submodule, `numpy.linalg`, which wraps optimized BLAS and LAPACK routines.\n",
    "\n",
    "Letâ€™s walk through a few key operations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.array([[3, 1], [1, 2]])\n",
    "b = np.array([9, 8])\n",
    "\n",
    "# Solve Ax = b\n",
    "x = np.linalg.solve(A, b)\n",
    "print('Solution x:', x)\n",
    "\n",
    "# Compute eigenvalues and eigenvectors\n",
    "vals, vecs = np.linalg.eig(A)\n",
    "print('\\nEigenvalues:', vals)\n",
    "print('Eigenvectors:\\n', vecs)\n",
    "\n",
    "# Verify that A * v = Î» * v for the first eigenpair\n",
    "v = vecs[:, 0]\n",
    "print('\\nCheck eigenpair:', np.allclose(A @ v, vals[0] * v))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understanding Results\n",
    "- `np.linalg.solve` is used instead of explicitly computing matrix inverses â€” itâ€™s faster and more numerically stable.\n",
    "- Eigenvalues reveal intrinsic properties of matrices, useful in **PCA**, **vibration analysis**, and more.\n",
    "\n",
    "Letâ€™s move to matrix decompositions next."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Singular Value Decomposition (SVD)\n",
    "U, S, VT = np.linalg.svd(A)\n",
    "print('U matrix:\\n', U)\n",
    "print('Singular values:', S)\n",
    "print('VT matrix:\\n', VT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVD is widely used in **dimensionality reduction**, **signal processing**, and **recommendation systems**. NumPyâ€™s efficient implementation lets you perform these operations on large datasets quickly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.3 Integration with Other Libraries\n",
    "\n",
    "NumPyâ€™s arrays are the **universal currency** in Pythonâ€™s data ecosystem. Letâ€™s explore interoperability with `pandas`, `matplotlib`, and `scipy`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "\n",
    "# Convert between pandas DataFrame and NumPy array\n",
    "df = pd.DataFrame(data, columns=['Feature1', 'Feature2', 'Feature3'])\n",
    "arr = df.values  # back to NumPy\n",
    "\n",
    "# Quick visualization using NumPy slicing\n",
    "plt.scatter(arr[:, 0], arr[:, 1], alpha=0.3)\n",
    "plt.title('Scatter Plot of Two Features')\n",
    "plt.xlabel('Feature 1')\n",
    "plt.ylabel('Feature 2')\n",
    "plt.show()\n",
    "\n",
    "# Apply SciPy statistical function on NumPy data\n",
    "t_stat, p_val = stats.ttest_ind(arr[:, 0], arr[:, 1])\n",
    "print('T-statistic:', t_stat)\n",
    "print('P-value:', p_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This example shows how NumPy integrates seamlessly across the **PyData stack**, allowing smooth transitions between data manipulation, visualization, and statistical analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.4 Performance Optimization\n",
    "\n",
    "NumPy is already fast â€” but you can make it even faster by understanding **vectorization**, **memory layout**, and **in-place operations**.\n",
    "\n",
    "Letâ€™s look at a simple optimization case study."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Naive loop approach\n",
    "x = np.random.rand(1_000_000)\n",
    "y = np.random.rand(1_000_000)\n",
    "\n",
    "# Vectorized version\n",
    "%timeit x + y  # Fast, C-level\n",
    "\n",
    "# Loop version\n",
    "def add_loop(a, b):\n",
    "    result = np.empty_like(a)\n",
    "    for i in range(len(a)):\n",
    "        result[i] = a[i] + b[i]\n",
    "    return result\n",
    "\n",
    "%timeit add_loop(x, y)  # Slow, Python-level"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Youâ€™ll observe that the vectorized version is **10â€“100Ã— faster** than the loop. NumPyâ€™s performance comes from executing operations in compiled C, rather than Pythonâ€™s interpreter.\n",
    "\n",
    "### Memory Efficiency Tips\n",
    "- Use `out=` parameters to avoid temporary arrays.\n",
    "- Prefer in-place operations (`A += B` instead of `A = A + B`).\n",
    "- Convert data types only when necessary (e.g., float32 instead of float64 to halve memory)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.5 Real-World Example: Image Normalization\n",
    "\n",
    "Letâ€™s bring everything together in a realistic scenario. Suppose youâ€™re processing RGB images represented as 3D arrays `(height, width, channels)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = np.random.randint(0, 255, size=(100, 100, 3), dtype=np.uint8)\n",
    "\n",
    "# Convert to float and normalize each color channel independently\n",
    "image_float = image.astype(float)\n",
    "channel_max = image_float.max(axis=(0, 1))  # shape (3,)\n",
    "normalized_img = image_float / channel_max  # broadcasting\n",
    "\n",
    "print('Original shape:', image.shape)\n",
    "print('Normalized pixel range:', normalized_img.min(), '-', normalized_img.max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This demonstrates how broadcasting, vectorization, and data type conversions come together in a real computational task â€” image preprocessing for machine learning or computer vision."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.6 Challenge Exercises\n",
    "\n",
    "Try these to solidify your understanding:\n",
    "\n",
    "1. Generate a dataset of 1000 samples with 5 features. Compute the covariance matrix using NumPy.\n",
    "2. Use `np.linalg.svd` to perform dimensionality reduction to 2 dimensions.\n",
    "3. Integrate with pandas: load your NumPy results into a DataFrame, then compute column correlations.\n",
    "4. Create a vectorized function that applies a nonlinear transformation `f(x) = xÂ² * sin(x)` to a large array, and benchmark it against a loop version.\n",
    "\n",
    "Reflect on how NumPyâ€™s design choices make each task efficient and expressive."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "**ðŸŽ¯ Final Review**\n",
    "\n",
    "By now, you should be able to:\n",
    "- Efficiently manipulate multi-dimensional data.\n",
    "- Use broadcasting and vectorization for speed.\n",
    "- Apply NumPy in scientific, statistical, and ML contexts.\n",
    "- Integrate NumPy seamlessly across the data science ecosystem.\n",
    "\n",
    "Congratulations! Youâ€™ve built a deep, intuitive understanding of NumPy â€” not just how to use it, but how it *thinks*. ðŸŒŸ"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.x"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
