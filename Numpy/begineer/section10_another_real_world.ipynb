{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üìä Section 9 ‚Äî Real-World Application: Analyzing Stock Market Data with NumPy\n",
    "\n",
    "---\n",
    "\n",
    "In this section, we‚Äôll apply NumPy to a **real-world-style data problem** ‚Äî analyzing simulated stock market data.\n",
    "\n",
    "You‚Äôll learn how NumPy powers workflows in **finance, data analytics, and quantitative research**, enabling fast numerical computations without pandas.\n",
    "\n",
    "We‚Äôll cover:\n",
    "- Generating and cleaning synthetic stock data\n",
    "- Calculating daily returns and moving averages\n",
    "- Identifying trends and volatility using vectorized logic\n",
    "- Performing efficient matrix-based portfolio analysis\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üß± Step 1: Simulating Stock Data\n",
    "\n",
    "Let‚Äôs start by creating synthetic closing prices for multiple stocks over 1 year (252 trading days). NumPy‚Äôs random module will help us simulate daily percentage changes (returns)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.random.seed(42)\n",
    "days = 252  # typical trading days per year\n",
    "stocks = ['AAPL', 'MSFT', 'GOOG', 'AMZN']\n",
    "n_stocks = len(stocks)\n",
    "\n",
    "# Simulate daily percentage changes ~ Normal(0.001, 0.02)\n",
    "daily_returns = np.random.normal(0.001, 0.02, size=(days, n_stocks))\n",
    "\n",
    "# Starting prices\n",
    "start_prices = np.array([150, 300, 2800, 3400])\n",
    "\n",
    "# Compute price series cumulatively\n",
    "price_series = start_prices * np.cumprod(1 + daily_returns, axis=0)\n",
    "\n",
    "price_series[:5]  # first 5 days"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üîç Observation\n",
    "Each column represents one stock‚Äôs daily closing price across 252 days. Vectorized cumulative multiplication makes this efficient ‚Äî no loops needed.\n",
    "\n",
    "Next, let‚Äôs compute **daily returns** from these prices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute daily percentage returns from price series\n",
    "returns = (price_series[1:] - price_series[:-1]) / price_series[:-1]\n",
    "print(\"Shape:\", returns.shape)\n",
    "returns[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìà Step 2: Moving Averages and Trend Detection\n",
    "\n",
    "A **moving average** smooths short-term fluctuations to reveal long-term trends. We can compute this efficiently with NumPy‚Äôs convolution function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def moving_average(data, window):\n",
    "    \"\"\"Compute simple moving average using convolution.\"\"\"\n",
    "    weights = np.ones(window) / window\n",
    "    return np.convolve(data, weights, mode='valid')\n",
    "\n",
    "# Example: 10-day moving average for AAPL\n",
    "aapl_prices = price_series[:, 0]\n",
    "ma_10 = moving_average(aapl_prices, 10)\n",
    "\n",
    "print(\"Original series length:\", len(aapl_prices))\n",
    "print(\"MA length:\", len(ma_10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also detect **upward trends** when the current price exceeds its moving average.\n",
    "\n",
    "This is a typical pattern in technical trading strategies ‚Äî all efficiently vectorized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trend_mask = aapl_prices[9:] > ma_10  # Compare price to its 10-day moving average\n",
    "trend_days = np.count_nonzero(trend_mask)\n",
    "print(f\"Days with upward trend: {trend_days}/{len(ma_10)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚ö° Step 3: Portfolio Analysis\n",
    "\n",
    "Let‚Äôs simulate a simple **portfolio** ‚Äî equal weights across all 4 stocks ‚Äî and compute its total daily return and risk (volatility)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = np.array([0.25, 0.25, 0.25, 0.25])\n",
    "\n",
    "# Portfolio daily returns (matrix multiplication)\n",
    "portfolio_returns = returns @ weights\n",
    "\n",
    "# Annualized statistics\n",
    "mean_daily = np.mean(portfolio_returns)\n",
    "std_daily = np.std(portfolio_returns)\n",
    "annual_return = mean_daily * 252\n",
    "annual_volatility = std_daily * np.sqrt(252)\n",
    "\n",
    "print(f\"Annualized Return: {annual_return:.2%}\")\n",
    "print(f\"Annualized Volatility: {annual_volatility:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üí° Discussion\n",
    "- Vectorized `@` matrix multiplication combines all stock returns at once.\n",
    "- `mean` and `std` use efficient C-level loops.\n",
    "- This pattern mirrors how professional quant libraries calculate risk metrics at scale."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîç Step 4: Correlation and Covariance\n",
    "\n",
    "Analyzing relationships between stocks helps in portfolio diversification. NumPy offers optimized covariance and correlation functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Covariance and correlation matrices\n",
    "cov_matrix = np.cov(returns.T)\n",
    "corr_matrix = np.corrcoef(returns.T)\n",
    "\n",
    "print(\"Covariance Matrix:\\n\", cov_matrix)\n",
    "print(\"\\nCorrelation Matrix:\\n\", corr_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üß† Under the Hood\n",
    "- Covariance is computed as `(X - mean)^T (X - mean) / (n - 1)`.\n",
    "- `np.cov` and `np.corrcoef` are built on BLAS/LAPACK routines, giving native-level performance.\n",
    "- The use of **row-major memory layout (C order)** makes these linear algebra operations cache-efficient."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚öôÔ∏è Step 5: Volatility Clustering\n",
    "\n",
    "Periods of high volatility often cluster together ‚Äî a real phenomenon in finance.\n",
    "\n",
    "We can detect these periods using **rolling standard deviation** computed vectorially."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rolling_std(data, window):\n",
    "    \"\"\"Compute rolling standard deviation using stride tricks.\"\"\"\n",
    "    shape = (data.size - window + 1, window)\n",
    "    strides = (data.strides[0], data.strides[0])\n",
    "    windows = np.lib.stride_tricks.as_strided(data, shape=shape, strides=strides)\n",
    "    return np.std(windows, axis=1)\n",
    "\n",
    "volatility_10 = rolling_std(portfolio_returns, 10)\n",
    "volatility_10[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This approach avoids explicit loops and creates a **view** over the data ‚Äî not a copy ‚Äî using NumPy stride tricks for high efficiency."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üß† Under the Hood\n",
    "\n",
    "- NumPy‚Äôs internal `ndarray` stores contiguous data in memory. Stride tricks reinterpret that same memory to create sliding windows.\n",
    "- `as_strided` is a powerful but advanced function ‚Äî used carefully, it enables operations like rolling metrics without copying large arrays.\n",
    "- This is one of the techniques used in libraries like `pandas` and `ta-lib` for efficient window functions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚ö†Ô∏è Best Practices / Pitfalls\n",
    "\n",
    "- Always **set a random seed** when generating synthetic data for reproducibility.\n",
    "- Avoid creating unnecessary copies ‚Äî vectorized math and views are faster and memory-efficient.\n",
    "- Use `np.matmul` or `@` instead of manual loops for portfolio or matrix operations.\n",
    "- Check array alignment (shapes, dtypes) before complex operations.\n",
    "- `np.ascontiguousarray()` can ensure proper layout for large computations.\n",
    "\n",
    "Following these practices yields code that‚Äôs **both readable and high-performance**, just like in production analytics systems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üí™ Challenge Exercise\n",
    "\n",
    "**Challenge 9.1**:\n",
    "\n",
    "1. Create a 5-stock portfolio with different random weights that sum to 1.\n",
    "2. Compute the daily and annualized return and volatility.\n",
    "3. Identify which stock contributes most to the overall volatility (hint: use covariance matrix).\n",
    "\n",
    "*Try this before viewing the next section or solutions.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "‚úÖ **Next Up:** We‚Äôll wrap up with a **comprehensive review and cheat sheet**, consolidating all key NumPy patterns you‚Äôve learned so far.\n",
    "\n",
    "`# --- End of Section 9 ‚Äî Continue to Final Review ---`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.x"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
