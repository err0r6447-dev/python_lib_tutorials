{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "7decf561",
      "metadata": {},
      "source": [
        "# Section 1 — The Pandas DataFrame: Core Structure and Philosophy\n",
        "\n",
        "**What this section covers (brief):**\n",
        "This section introduces the Pandas `Series` and `DataFrame` as labeled, tabular data containers built on top of NumPy. We'll create DataFrames, inspect their structure and dtypes, access rows/columns, and perform basic column operations. The examples use a consistent small retail-sales dataset theme so you can reuse it as we progress through later sections."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9d0e3e82",
      "metadata": {},
      "source": [
        "## Subtopics\n",
        "\n",
        "1. **DataFrame & Series essentials** — creation, shape, `dtypes`, `info`, and `describe()` for quick inspection.\n",
        "2. **Column & row access** — `.loc`, `.iloc`, attribute access, and boolean masks for selection.\n",
        "3. **Basic transformations** — adding/renaming columns, `astype` conversions, handling `NaN`s.\n",
        "4. **Practical patterns** — consistent dataset theme and idiomatic patterns for readability and reproducibility."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6e235ac8",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Core imports and display configuration\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Helpful display options for notebooks (optional)\n",
        "pd.set_option('display.max_columns', 50)\n",
        "pd.set_option('display.width', 120)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "14aca5ce",
      "metadata": {},
      "source": [
        "### Creating DataFrames\n",
        "\n",
        "We'll create a small retail sales DataFrame; in real life you'd use `pd.read_csv()` or `pd.read_sql()`, but for self-contained examples we generate the data programmatically so the code is runnable anywhere."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fa60cd46",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create a simple retail sales DataFrame (runnable example)\n",
        "rng = np.random.default_rng(seed=42)\n",
        "n = 12\n",
        "df = pd.DataFrame({\n",
        "    'order_id': np.arange(1001, 1001 + n),\n",
        "    'customer_id': rng.integers(200, 210, size=n),\n",
        "    'product': rng.choice(['T-shirt', 'Mug', 'Cap', 'Notebook'], size=n),\n",
        "    'quantity': rng.integers(1, 5, size=n),\n",
        "    'price': np.round(rng.uniform(5.0, 40.0, size=n), 2),\n",
        "    'order_date': pd.date_range('2023-01-15', periods=n, freq='7D')\n",
        "})\n",
        "\n",
        "# Introduce a couple of NaNs to illustrate missing data handling\n",
        "df.loc[[2, 7], 'price'] = np.nan\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f74879f9",
      "metadata": {},
      "source": [
        "### Inspecting a DataFrame — quick checks\n",
        "\n",
        "Use `head()`, `info()`, `dtypes`, and `describe()` to understand shape and types. `info()` is especially useful for spotting `object` dtype columns which might represent strings, datetimes, or mixed types."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1f80d295",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Quick inspection utilities\n",
        "print('Shape:', df.shape)\n",
        "display(df.head())\n",
        "print('\\nInfo:')\n",
        "display(df.info())\n",
        "print('\\nDtypes:')\n",
        "display(df.dtypes)\n",
        "print('\\nNumeric summary:')\n",
        "display(df.describe(include=[np.number]))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b2ab3625",
      "metadata": {},
      "source": [
        "### Column access and selection patterns\n",
        "\n",
        "Common idioms:\n",
        "- `df['col']` — returns a `Series`.\n",
        "- `df[['a','b']]` — returns a `DataFrame` with selected columns.\n",
        "- `df.loc[row_label, col_label]` — label-based selection.\n",
        "- `df.iloc[row_idx, col_idx]` — integer positional selection.\n",
        "- Boolean masks (`df[df['col'] > val]`) for filtered views."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e10bf53b",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Column access examples\n",
        "series_price = df['price']          # Series\n",
        "subset = df[['order_id', 'product', 'price']]  # DataFrame\n",
        "row3 = df.iloc[2]                  # third row (0-based)\n",
        "by_customer_200 = df[df['customer_id'] == 200]\n",
        "\n",
        "# Label-based access example (loc)\n",
        "first_row_price = df.loc[0, 'price']\n",
        "\n",
        "series_price, subset.head(), row3.to_dict(), len(by_customer_200), first_row_price"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bff826e8",
      "metadata": {},
      "source": [
        "### Basic transformations: adding columns, renaming, and dtype conversions\n",
        "\n",
        "Idiomatic patterns are important for readability. Avoid in-place changes unless necessary (explicit `inplace=True` is discouraged in many cases — prefer assignment to a new variable or to the same name to make transformations explicit)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "24e3065c",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Add a derived column (total = quantity * price), carefully handling NaNs\n",
        "df = df.copy()  # make an explicit copy to avoid surprises for learners\n",
        "df['total'] = df['quantity'] * df['price']\n",
        "\n",
        "# Fill missing prices with a sentinel or estimate (example: median) before certain ops\n",
        "median_price = df['price'].median(skipna=True)\n",
        "df['price_filled'] = df['price'].fillna(median_price)\n",
        "df['total_filled'] = df['quantity'] * df['price_filled']\n",
        "\n",
        "# Rename columns cleanly\n",
        "df = df.rename(columns={'price': 'price_orig', 'price_filled': 'price'})\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cabafbc1",
      "metadata": {},
      "source": [
        "## Real-World Problem 1 — Sales summary by product and month\n",
        "\n",
        "**Problem:** Given a sales DataFrame (`order_id`, `order_date`, `product`, `quantity`, `price`), compute monthly revenue per product and show the top 3 product-month combinations by revenue.\n",
        "\n",
        "This reinforces grouping/aggregation, datetime handling, and sorting."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "03f498e1",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Prepare data (ensure we have a proper datetime index/column)\n",
        "df1 = df.copy()\n",
        "df1['order_month'] = df1['order_date'].dt.to_period('M')\n",
        "\n",
        "# Compute revenue using filled prices to avoid NaNs\n",
        "df1['revenue'] = df1['quantity'] * df1['price']\n",
        "\n",
        "# Group by product and month, then sum revenue\n",
        "monthly = (\n",
        "    df1.groupby(['order_month', 'product'], as_index=False)\n",
        "       .agg(total_revenue=('revenue', 'sum'), total_qty=('quantity', 'sum'))\n",
        ")\n",
        "\n",
        "# Convert order_month back to string for nicer display then sort\n",
        "monthly['order_month'] = monthly['order_month'].astype(str)\n",
        "top3 = monthly.sort_values('total_revenue', ascending=False).head(3)\n",
        "monthly, top3"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8e695197",
      "metadata": {},
      "source": [
        "## Real-World Problem 2 — Detect customers with declining purchase trend\n",
        "\n",
        "**Problem:** For each customer, compute monthly total spend; identify customers whose spend declined for at least two consecutive months. This uses pivoting/time grouping and boolean masks to find trends."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5297c284",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Prepare a slightly larger sample to illustrate trends (simulate more history)\n",
        "rng = np.random.default_rng(1)\n",
        "dates = pd.date_range('2023-01-01', periods=90, freq='D')\n",
        "sim = pd.DataFrame({\n",
        "    'order_date': rng.choice(dates, size=200),\n",
        "    'customer_id': rng.integers(1000, 1010, size=200),\n",
        "    'quantity': rng.integers(1, 4, size=200),\n",
        "    'price': np.round(rng.uniform(5, 50, size=200), 2)\n",
        "})\n",
        "sim['month'] = sim['order_date'].dt.to_period('M')\n",
        "sim['revenue'] = sim['quantity'] * sim['price']\n",
        "\n",
        "# Aggregate: customer x month revenue\n",
        "cust_month = sim.groupby(['customer_id', 'month'], as_index=False).agg(revenue=('revenue', 'sum'))\n",
        "pivot = cust_month.pivot(index='customer_id', columns='month', values='revenue').fillna(0)\n",
        "\n",
        "# Detect customers with at least two consecutive months of decline\n",
        "decline_customers = []\n",
        "for cid, row in pivot.iterrows():\n",
        "    # Convert to numpy array for easy difference checks\n",
        "    arr = row.values\n",
        "    # compute month-to-month differences (negative => decline)\n",
        "    diffs = np.diff(arr)\n",
        "    # check if there's any place with two consecutive negative diffs\n",
        "    if np.any((diffs[:-1] < 0) & (diffs[1:] < 0)):\n",
        "        decline_customers.append(cid)\n",
        "\n",
        "pivot.head(), decline_customers[:10]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e397cc5c",
      "metadata": {},
      "source": [
        "## Under the Hood — How a DataFrame stores data (concise)\n",
        "\n",
        "- A `DataFrame` is conceptually a dict-like container of `Series` objects that share an index. Underneath, many columns are backed by NumPy `ndarray`s (or extension arrays for some dtypes).\n",
        "- Pandas uses block managers / columnar layout to store homogeneous blocks efficiently. Numeric columns are usually contiguous `ndarray`s — operations on them are fast because NumPy vectorized routines are used.\n",
        "- `object` dtype columns are pointers to Python objects and are much slower for numeric work. Prefer native numeric dtypes (`int`, `float`) or `Categorical` for repeated strings.\n",
        "- Index alignment: when you do operations across columns/rows, Pandas aligns on index labels — this is powerful but may create hidden costs if indexes are not simple RangeIndex."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9ef42042",
      "metadata": {},
      "source": [
        "## Best Practices / Common Pitfalls\n",
        "\n",
        "- **Prefer vectorized operations** (column arithmetic) over `for` loops or repeated `df.loc[...]` assignments — vectorized ops use NumPy under the hood and are far faster.\n",
        "- **Be explicit with copies**: `df2 = df` does **not** copy — use `df.copy()` when you need a separate object to avoid SettingWithCopy warnings.\n",
        "- **Watch `object` dtype**: convert string-like categorical columns to `pd.Categorical` when appropriate to save memory and speed up groupby operations.\n",
        "- **Avoid chaining ambiguous assignments** (e.g., `df[df['a'] > 0]['b'] = 1`) — use `.loc` to set values safely: `df.loc[df['a'] > 0, 'b'] = 1`.\n",
        "- **Always inspect `dtypes`** after reading data — automatic inference can produce unexpected `object` or `float` dtypes for what should be integers or datetimes."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b57e5161",
      "metadata": {},
      "source": [
        "## Challenge Exercise (no solution here)\n",
        "\n",
        "Using the initial small `df` (the retail sample at the top):\n",
        "1. Create a clean `orders_clean` DataFrame that:\n",
        "   - Converts `order_date` to `datetime` if not already,\n",
        "   - Fills missing `price` values using a reasonable strategy,\n",
        "   - Adds a `weekday` column (name of the day),\n",
        "   - Ensures `customer_id` is of integer dtype.\n",
        "2. Then write a function `top_customers(df, n=5)` that returns the top `n` customers by total spend. Make sure your function is robust to `NaN`s and unexpected dtypes.\n",
        "\n",
        "_Hint:_ Compose operations into a clear pipeline using local assignment (avoid chained assignments)."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "137f7b41",
      "metadata": {},
      "source": [
        "# --- End of Section 1 — Continue to Section 2 ---"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": ""
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
