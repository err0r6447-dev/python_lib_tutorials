{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üìò Section 9: Advanced Data Cleaning, Outlier Detection & Data Validation\n",
    "\n",
    "**Level:** Advanced\n",
    "\n",
    "In this section, we will master **data cleaning, outlier detection, and validation** using Pandas. These techniques ensure data integrity and consistency before analysis or modeling.\n",
    "\n",
    "We'll cover:\n",
    "- Handling inconsistent data types\n",
    "- Detecting and treating outliers\n",
    "- Dealing with duplicates and missing patterns\n",
    "- Data validation and constraints\n",
    "- Real-world case studies: cleaning sales and sensor data\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîπ 9.1 Detecting Data Type Issues and Conversion\n",
    "\n",
    "Real-world data often comes with **mixed types**, such as numbers stored as strings or inconsistent formats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Simulated dataset with mixed data types\n",
    "df = pd.DataFrame({\n",
    "    'product_id': ['P001', 'P002', 'P003', 'P004', 'P005'],\n",
    "    'price': ['100', '200', 'N/A', '350', 'Two Hundred'],\n",
    "    'quantity': [10, 5, np.nan, 8, 3]\n",
    "})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning and Converting to Numeric Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Coerce invalid entries to NaN\n",
    "df['price'] = pd.to_numeric(df['price'], errors='coerce')\n",
    "\n",
    "# Fill NaN with median value\n",
    "df['price'] = df['price'].fillna(df['price'].median())\n",
    "df.info()\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîπ 9.2 Detecting Missing Patterns\n",
    "\n",
    "Identifying missing values is crucial for choosing an appropriate imputation or dropping strategy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_missing = pd.DataFrame({\n",
    "    'A': [1, 2, np.nan, 4, np.nan],\n",
    "    'B': [np.nan, 5, 6, np.nan, 8],\n",
    "    'C': ['x', 'y', 'z', 'y', np.nan]\n",
    "})\n",
    "\n",
    "# Visualize missingness\n",
    "print(df_missing.isnull())\n",
    "print('\\nTotal missing per column:')\n",
    "print(df_missing.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fill Patterns Strategically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forward fill for time-series-like data\n",
    "df_missing_ffill = df_missing.fillna(method='ffill')\n",
    "\n",
    "# Conditional filling\n",
    "df_missing['A'] = df_missing['A'].fillna(df_missing['A'].mean())\n",
    "df_missing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîπ 9.3 Outlier Detection with IQR and Z-Score\n",
    "\n",
    "Outliers can distort your analysis or models. Pandas works well with statistical techniques like **IQR** and **Z-score** for detection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "sales = pd.DataFrame({'revenue': np.random.normal(1000, 100, 100)})\n",
    "# Add some extreme outliers\n",
    "sales.loc[[10, 20, 50], 'revenue'] = [3000, 50, 5000]\n",
    "\n",
    "# IQR Method\n",
    "Q1 = sales['revenue'].quantile(0.25)\n",
    "Q3 = sales['revenue'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "outliers = sales[(sales['revenue'] < (Q1 - 1.5 * IQR)) | (sales['revenue'] > (Q3 + 1.5 * IQR))]\n",
    "print('Detected outliers:')\n",
    "display(outliers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handling Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cap outliers using quantiles\n",
    "sales['revenue_capped'] = np.where(sales['revenue'] > Q3 + 1.5 * IQR, Q3 + 1.5 * IQR, sales['revenue'])\n",
    "sales['revenue_capped'] = np.where(sales['revenue_capped'] < Q1 - 1.5 * IQR, Q1 - 1.5 * IQR, sales['revenue_capped'])\n",
    "\n",
    "sales[['revenue', 'revenue_capped']].head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîπ 9.4 Validating Data Integrity with Rules\n",
    "\n",
    "Ensure the dataset follows logical and domain-specific rules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "products = pd.DataFrame({\n",
    "    'product_id': ['A', 'B', 'C', 'D'],\n",
    "    'price': [50, -10, 30, 0],\n",
    "    'quantity': [10, 5, 0, -3]\n",
    "})\n",
    "\n",
    "# Rule 1: Price and quantity should be positive\n",
    "invalid = products[(products['price'] <= 0) | (products['quantity'] <= 0)]\n",
    "print('Invalid entries:')\n",
    "display(invalid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚öôÔ∏è Under the Hood\n",
    "\n",
    "- Pandas uses **NumPy masked arrays** for missing data handling.\n",
    "- `pd.to_numeric(errors='coerce')` leverages fast C-level parsing.\n",
    "- Boolean indexing and `np.where()` are **vectorized operations**, minimizing Python loops.\n",
    "- IQR-based filtering is efficient because it uses **quantile interpolation** in C.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üíº Real-World Problem 1 ‚Äî Customer Transactions Cleanup\n",
    "\n",
    "**Scenario:** You receive a messy CSV file of customer transactions. Some records have missing values, typos in prices, and duplicate rows.\n",
    "\n",
    "**Goal:**\n",
    "1. Identify and remove duplicates.\n",
    "2. Convert `price` to numeric.\n",
    "3. Drop rows with invalid or incomplete data.\n",
    "4. Summarize total revenue by customer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame({\n",
    "    'customer': ['Alice', 'Bob', 'Alice', 'Charlie', 'Bob', 'Bob'],\n",
    "    'price': ['200', '100', 'Two Hundred', '150', None, '100'],\n",
    "    'quantity': [2, 1, 2, 1, 1, 1]\n",
    "})\n",
    "\n",
    "# Clean duplicates\n",
    "data = data.drop_duplicates()\n",
    "\n",
    "# Convert and clean\n",
    "data['price'] = pd.to_numeric(data['price'], errors='coerce')\n",
    "data = data.dropna()\n",
    "data['total'] = data['price'] * data['quantity']\n",
    "\n",
    "# Revenue summary\n",
    "revenue_summary = data.groupby('customer')['total'].sum()\n",
    "revenue_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üåç Real-World Problem 2 ‚Äî IoT Sensor Outlier Filtering\n",
    "\n",
    "**Scenario:** IoT sensors sometimes send corrupted readings. You need to identify and cap anomalies.\n",
    "\n",
    "**Goal:** Use statistical techniques to detect and fix faulty temperature readings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate temperature readings\n",
    "temp = pd.DataFrame({'reading': np.append(np.random.normal(25, 2, 100), [100, -10, 60])})\n",
    "\n",
    "# Detect outliers using Z-score\n",
    "mean = temp['reading'].mean()\n",
    "std = temp['reading'].std()\n",
    "temp['zscore'] = (temp['reading'] - mean) / std\n",
    "\n",
    "# Cap outliers beyond 3 std\n",
    "temp['cleaned'] = np.where(temp['zscore'].abs() > 3, mean, temp['reading'])\n",
    "temp.head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚úÖ Best Practices / Pitfalls\n",
    "\n",
    "‚úÖ Always inspect data types with `df.info()` before cleaning.\n",
    "‚úÖ Use `errors='coerce'` to safely convert invalid numeric data.\n",
    "‚úÖ Use **IQR** or **Z-score** methods to handle outliers instead of naive trimming.\n",
    "‚ö†Ô∏è Don‚Äôt over-impute missing data ‚Äî it can introduce bias.\n",
    "‚öôÔ∏è Use `DataFrame.query()` for cleaner conditional validation.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üí™ Challenge Exercise\n",
    "\n",
    "**Task:** You‚Äôre analyzing product reviews. Some entries have missing text, negative ratings, or duplicates.\n",
    "1. Drop duplicates.\n",
    "2. Ensure ratings are within [1, 5].\n",
    "3. Fill missing review text with 'No Review'.\n",
    "4. Compute average rating per product.\n",
    "\n",
    "_(Try to implement this step-by-step in your own notebook!)_\n",
    "\n",
    "---\n",
    "# --- End of Section 9 ‚Äî Continue to Section 10 ---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
